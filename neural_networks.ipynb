{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copia_di_08_bayesian_neural_networks.ipynb","provenance":[{"file_id":"1445XAglror7uSGbraZhWcNz9qOnuZc_y","timestamp":1626935287040}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"gBGaF5W1nyw0"},"source":["# Bayesian Neural Networks + SVI inference"]},{"cell_type":"code","metadata":{"id":"nF6e9JtynBAD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627026137459,"user_tz":-120,"elapsed":9915,"user":{"displayName":"Matteo Marturini","photoUrl":"","userId":"15766514266173803551"}},"outputId":"a280bd0a-d124-4483-995d-0ed100e9e522"},"source":["#@title Imports\n","import os\n","import sys\n","import json\n","import copy\n","import random\n","import numpy as np\n","import keras\n","from tqdm import tqdm\n","\n","#!pip install torch==1.8.1\n","import torch\n","torch.set_default_dtype(torch.float32)\n","from torch.utils.data import DataLoader\n","from torch import nn\n","import torch.nn.functional as nnf\n","softplus = torch.nn.Softplus()\n","import torch.optim as torchopt\n","\n","!pip install pyro-ppl==1.3.0\n","import pyro\n","from pyro import poutine\n","import pyro.distributions as dist\n","from pyro.optim import Adam\n","import pyro.optim as pyroopt\n","from pyro.nn import PyroModule\n","from pyro.infer import SVI, Trace_ELBO, TraceMeanField_ELBO\n","from pyro.distributions import Normal, Categorical, OneHotCategorical\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","#from keras.datasets import mnist\n","from tensorflow.keras.datasets import fashion_mnist\n","from tensorflow.keras.utils import to_categorical\n","import matplotlib.pyplot as plt"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting pyro-ppl==1.3.0\n","  Downloading pyro_ppl-1.3.0-py3-none-any.whl (495 kB)\n","\u001b[?25l\r\u001b[K     |▋                               | 10 kB 28.8 MB/s eta 0:00:01\r\u001b[K     |█▎                              | 20 kB 30.5 MB/s eta 0:00:01\r\u001b[K     |██                              | 30 kB 33.3 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 40 kB 35.0 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 51 kB 37.1 MB/s eta 0:00:01\r\u001b[K     |████                            | 61 kB 38.9 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 71 kB 36.8 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 81 kB 33.8 MB/s eta 0:00:01\r\u001b[K     |██████                          | 92 kB 32.7 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 102 kB 33.6 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 112 kB 33.6 MB/s eta 0:00:01\r\u001b[K     |████████                        | 122 kB 33.6 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 133 kB 33.6 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 143 kB 33.6 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 153 kB 33.6 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 163 kB 33.6 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 174 kB 33.6 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 184 kB 33.6 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 194 kB 33.6 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 204 kB 33.6 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 215 kB 33.6 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 225 kB 33.6 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 235 kB 33.6 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 245 kB 33.6 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 256 kB 33.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 266 kB 33.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 276 kB 33.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 286 kB 33.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 296 kB 33.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 307 kB 33.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 317 kB 33.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 327 kB 33.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 337 kB 33.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 348 kB 33.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 358 kB 33.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 368 kB 33.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 378 kB 33.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 389 kB 33.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 399 kB 33.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 409 kB 33.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 419 kB 33.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 430 kB 33.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 440 kB 33.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 450 kB 33.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 460 kB 33.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 471 kB 33.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 481 kB 33.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 491 kB 33.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 495 kB 33.6 MB/s \n","\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from pyro-ppl==1.3.0) (3.3.0)\n","Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.7/dist-packages (from pyro-ppl==1.3.0) (4.41.1)\n","Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from pyro-ppl==1.3.0) (1.9.0+cu102)\n","Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from pyro-ppl==1.3.0) (1.19.5)\n","Collecting pyro-api>=0.1.1\n","  Downloading pyro_api-0.1.2-py3-none-any.whl (11 kB)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4.0->pyro-ppl==1.3.0) (3.7.4.3)\n","Installing collected packages: pyro-api, pyro-ppl\n","Successfully installed pyro-api-0.1.2 pyro-ppl-1.3.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4Tf-QMuIWVfH","executionInfo":{"status":"ok","timestamp":1627026715060,"user_tz":-120,"elapsed":218,"user":{"displayName":"Matteo Marturini","photoUrl":"","userId":"15766514266173803551"}}},"source":["from keras.datasets import mnist"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c6Wz-aI5T9am","executionInfo":{"status":"ok","timestamp":1627026161060,"user_tz":-120,"elapsed":20925,"user":{"displayName":"Matteo Marturini","photoUrl":"","userId":"15766514266173803551"}},"outputId":"659838a4-9b81-4433-f343-3a47d4e774bd"},"source":["# set device \n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)\n","\n","# mount drive folder\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["cuda:0\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aQd6odvuHVC8","executionInfo":{"status":"ok","timestamp":1627026164791,"user_tz":-120,"elapsed":231,"user":{"displayName":"Matteo Marturini","photoUrl":"","userId":"15766514266173803551"}}},"source":["path = \"/content/drive/My Drive/Copia_di_08_bayesian_neural_networks\""],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AZVLxnTsT9yY"},"source":["### Load fashion-MNIST dataset"]},{"cell_type":"code","metadata":{"id":"zwPJ1xatnKJJ","colab":{"base_uri":"https://localhost:8080/","height":316},"executionInfo":{"status":"ok","timestamp":1627026726331,"user_tz":-120,"elapsed":949,"user":{"displayName":"Matteo Marturini","photoUrl":"","userId":"15766514266173803551"}},"outputId":"bb27a1b2-c035-462a-9e33-8e8cc770b7ef"},"source":["batch_size=128\n","\n","\n","def load_mnist(n_inputs=60000):\n","    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n","    output_size = 10\n","\n","    # subset, select the first n_inputs rows\n","    x_train = x_train[:n_inputs]\n","    x_test = x_test[:n_inputs]\n","    y_train = y_train[:n_inputs]\n","    y_test = y_test[:n_inputs]\n","\n","    # one hot encoding\n","    # One hot encoding is a process by which categorical variables are converted\n","    # into a form that could be provided to ML algorithms to do a better job in prediction\n","    y_train = to_categorical(y_train, output_size)\n","    y_test = to_categorical(y_test, output_size)\n","\n","    # convert to torch and set dtype\n","    x_train = torch.from_numpy(x_train.astype('float32'))\n","    x_test = torch.from_numpy(x_test.astype('float32'))\n","    y_train = torch.from_numpy(y_train.astype('long'))\n","    y_test = torch.from_numpy(y_test.astype('long'))\n","\n","    # convert pixels to 0-1 range\n","    x_train /= 255\n","    x_test /= 255\n","\n","    # expand channels dimension\n","    ## e.g.    (100, 28, 28) = (n_images, row_pxls, col_pixels) \n","    ## becomes (100, 1, 28, 28) = (n_images, n_channels, row_pxls, col_pixels) \n","    x_train = x_train.unsqueeze(1)\n","    x_test = x_test.unsqueeze(1)\n","\n","    # input/output shapes\n","    input_shape = x_train[0].shape # = (1, 28, 28)\n","    \n","    return x_train, y_train, x_test, y_test, input_shape, output_size\n","\n","# plot image from mnist\n","x_train = load_mnist(n_inputs=1)[0]\n","plt.imshow(x_train[0].squeeze(), cmap='gray')\n","plt.show()"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11493376/11490434 [==============================] - 0s 0us/step\n","11501568/11490434 [==============================] - 0s 0us/step\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"cHXvUDETUHVo"},"source":["### Deterministic Neural Network\n"]},{"cell_type":"code","metadata":{"id":"hZbkjbzsvU4S","executionInfo":{"status":"ok","timestamp":1627026732689,"user_tz":-120,"elapsed":228,"user":{"displayName":"Matteo Marturini","photoUrl":"","userId":"15766514266173803551"}}},"source":["class DeterministicNetwork(nn.Module):\n","  \n","    def __init__(self, input_shape, hidden_size, output_size):\n","\n","        # initialize nn.Module\n","        super(DeterministicNetwork, self).__init__()\n","\n","        input_size = input_shape[0]*input_shape[1]*input_shape[2] # 784\n","        channels = input_shape[0] # 1 \n","    \n","        # architecture\n","        self.model = nn.Sequential(\n","                    nn.Conv2d(channels, 32, kernel_size=5),\n","                    nn.LeakyReLU(),\n","                    nn.MaxPool2d(kernel_size=2),\n","                    nn.Conv2d(32, hidden_size, kernel_size=5),\n","                    nn.LeakyReLU(),\n","                    nn.MaxPool2d(kernel_size=2, stride=1),\n","                    nn.Flatten(),\n","                    nn.Linear(int(hidden_size/(4*4))*input_size, output_size))\n","    \n","        self.name = \"deterministic_network\"\n","\n","    def forward(self, inputs, *args, **kwargs):\n","        \"\"\" Compute predictions on `inputs`. \"\"\"\n","        return self.model(inputs)\n","\n","    def train(self, x_train, y_train, lr, epochs, device):\n","        \"\"\" Train network. \"\"\"\n","        random.seed(0)\n","\n","        # DataLoader combines a dataset and a sampler, and provides an \n","        # iterable over the given dataset\n","        train_loader = DataLoader(dataset=list(zip(x_train, y_train)), \n","                                  batch_size=batch_size, shuffle=False)\n","\n","        # send network to device\n","        self.to(device)\n","\n","        # set optimizer and loss function for training\n","        optimizer = torchopt.Adam(params=self.parameters(), lr=lr)\n","        loss_fn = nn.CrossEntropyLoss()\n","        \n","        for epoch in range(epochs):\n","            total_loss = 0.0\n","\n","            for x_batch, y_batch in train_loader:\n","\n","                # send data to device\n","                x_batch = x_batch.to(device)\n","                y_batch = y_batch.to(device).argmax(-1)\n","\n","                ### loss optimization ###\n","                outputs = self.forward(x_batch) # forward pass\n","\n","                # reset gradients w.r.t. network parameters\n","                optimizer.zero_grad() \n","\n","                # loss on predicted labels vs true labels\n","                loss = loss_fn(outputs, y_batch) \n","\n","                # backward pass: computes the derivative of the loss w.r.t.\n","                # the parameters using backpropagation.\n","                loss.backward() \n","\n","                # update parameters, i.e. take a step based on the gradients \n","                # of the parameters.\n","                optimizer.step() \n","                #########################\n","\n","                # update training loss\n","                total_loss += loss.data.item() / len(train_loader.dataset)\n","        \n","            print(f\"\\n[Epoch {epoch + 1}]\\t loss: {total_loss:.8f}\", end=\"\\t\")\n","\n","    def save(self, savedir):\n","        \"\"\" Save network weights. \"\"\"\n","        self.to(\"cpu\") # send network to cpu\n","        os.makedirs(savedir, exist_ok=True)\n","        torch.save(self.state_dict(), os.path.join(savedir, self.name+\"_weights.pt\"))\n","      \n","    def load(self, savedir, device):\n","        \"\"\" Load network weights. \"\"\"\n","        self.load_state_dict(torch.load(os.path.join(savedir, self.name+\"_weights.pt\")))\n","        self.to(device)\n","      \n","    def evaluate(self, x_test, y_test, device, *args, **kwargs):\n","        \"\"\" Evaluate network on test set. \"\"\"\n","        random.seed(0)\n","        self.to(device)\n","\n","        test_loader = DataLoader(dataset=list(zip(x_test, y_test)), batch_size=batch_size, shuffle=False)       \n","\n","        # disable gradients computation\n","        with torch.no_grad():\n","\n","            correct_predictions = 0.0\n","\n","            # compute predictions on mini-batch\n","            for x_batch, y_batch in test_loader:\n","                x_batch = x_batch.to(device)\n","                y_batch = y_batch.to(device).argmax(-1)\n","                outputs = self(x_batch) # self.forward(x_batch)\n","                predictions = outputs.argmax(dim=-1)\n","                correct_predictions += (predictions == y_batch).sum()\n","\n","            accuracy = 100 * correct_predictions / len(test_loader.dataset)\n","\n","        return accuracy"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"f7IpvNvxUPDs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627026788038,"user_tz":-120,"elapsed":51779,"user":{"displayName":"Matteo Marturini","photoUrl":"","userId":"15766514266173803551"}},"outputId":"321d3c1c-d906-429d-ac03-94ebcf06cccf"},"source":["x_train, y_train, x_test, y_test, input_shape, output_size = load_mnist(n_inputs=60000)\n","det_model = DeterministicNetwork(input_shape=input_shape, hidden_size=512, output_size=output_size)\n","\n","det_model.train(x_train=x_train, y_train=y_train, lr=0.01, epochs=10, device=device)\n","det_model.save(savedir=path)\n","det_model.load(savedir=path, device=device)\n","\n","accuracy = det_model.evaluate(x_test, y_test, device=device)\n","print(\"\\nTest accuracy: %.2f%%\" % (accuracy))"],"execution_count":12,"outputs":[{"output_type":"stream","text":["\n","[Epoch 1]\t loss: 0.00254692\t\n","[Epoch 2]\t loss: 0.00052096\t\n","[Epoch 3]\t loss: 0.00038678\t\n","[Epoch 4]\t loss: 0.00074207\t\n","[Epoch 5]\t loss: 0.00044139\t\n","[Epoch 6]\t loss: 0.00045326\t\n","[Epoch 7]\t loss: 0.00126486\t\n","[Epoch 8]\t loss: 0.00121309\t\n","[Epoch 9]\t loss: 0.00057106\t\n","[Epoch 10]\t loss: 0.00063246\t\n","Test accuracy: 98.58%\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eivgW9rGI6j1"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EERqqBN2sZNP"},"source":["### Bayesian Neural Network"]},{"cell_type":"code","metadata":{"id":"O1ZiGB7Nszr-","executionInfo":{"status":"ok","timestamp":1627026808300,"user_tz":-120,"elapsed":587,"user":{"displayName":"Matteo Marturini","photoUrl":"","userId":"15766514266173803551"}}},"source":["class BayesianNetwork(PyroModule):\n","\n","    def __init__(self, input_shape, hidden_size, output_size):\n","        # initialize PyroModule\n","        super(BayesianNetwork, self).__init__()\n","\n","        # BayesianNetwork extends PyroModule class\n","        self.det_network = DeterministicNetwork(input_shape, hidden_size, output_size)\n","\n","        self.name = \"bayesian_network\"\n","      \n","    def model(self, x_data, y_data):\n","        \"\"\" Sets prior distributions and conditions on the observations. \"\"\"\n","        priors = {}\n","    \n","        # set Gaussian priors on the weights of self.det_network\n","        for key, value in self.det_network.state_dict().items():\n","            loc = torch.zeros_like(value)\n","            scale = torch.ones_like(value)\n","            prior = Normal(loc=loc, scale=scale)\n","            priors.update({str(key):prior})\n","\n","        # pyro.random_module places `priors` over the parameters of the nn.Module \n","        # self.det_network and returns a distribution, which upon calling \n","        # samples a new nn.Module (`lifted_module`)\n","        lifted_module = pyro.random_module(\"module\", self.det_network, priors)()\n","\n","        # samples are conditionally independent w.r.t. the observed data\n","        with pyro.plate(\"data\", len(x_data)):\n","            out = lifted_module(x_data) # out.shape = (batch_size, num_classes)\n","            obs = pyro.sample(\"obs\", Categorical(logits=out), obs=y_data) # obs.shape = (batch_size)\n","\n","    def guide(self, x_data, y_data=None):\n","        \"\"\" Samples from the Variational distribution and returns predictions. \"\"\"\n","\n","        # take random samples of det_network's weights from the chosen variational family\n","        dists = {}\n","        for key, value in self.det_network.state_dict().items():\n","\n","            # torch.randn_like(x) builds a random tensor whose shape equals x.shape\n","            loc = pyro.param(str(f\"{key}_loc\"), torch.randn_like(value)) \n","            scale = pyro.param(str(f\"{key}_scale\"), torch.randn_like(value))\n","\n","            # softplus is a smooth approximation to the ReLU function\n","            # which constraints the scale tensor to positive values\n","            distr = Normal(loc=loc, scale=softplus(scale))\n","\n","            # add key-value pair to the samples dictionary\n","            dists.update({str(key):distr})\n","\n","        # define a random module from the dictionary of distributions\n","        lifted_module = pyro.random_module(\"module\", self.det_network, dists)()\n","\n","        with pyro.plate(\"data\", len(x_data)):\n","\n","            # compute predictions on `x_data`\n","            out = lifted_module(x_data)\n","            preds = nnf.softmax(out, dim=-1)\n","            return preds\n","        \n","    def forward(self, inputs, n_samples=10, sample_idx=None, avg_prediction=True):\n","        \"\"\" Compute predictions on `inputs`. \n","        `n_samples` is the number of samples from the posterior distribution.\n","        If `sample_idx` is provided, it is used as a seed for sampling a single\n","        model from the Variational family.\n","        If `avg_prediction` is True, it returns the average prediction on \n","        `inputs`, otherwise it returns all predictions \n","        \"\"\"\n","        if sample_idx:\n","            # set random seeds for both torch and pyro\n","            random.seed(sample_idx)\n","            pyro.set_rng_seed(sample_idx)    \n","\n","            # sample from the guide() function and evaluate it on `inputs`        \n","            guide_trace = poutine.trace(self.guide).get_trace(inputs)  \n","\n","            # get the output prediction from the guide() function\n","            preds = [guide_trace.nodes['_RETURN']['value']]\n","        \n","        else:\n","            preds = []\n","            # take multiple samples\n","            for _ in range(n_samples):         \n","                guide_trace = poutine.trace(self.guide).get_trace(inputs)  \n","                preds.append(guide_trace.nodes['_RETURN']['value'])\n","        \n","        # list of tensors to tensor\n","        # preds.shape = (n_samples, batch_size, n_classes)\n","        preds = torch.stack(preds)\n","\n","        # return predictions \n","        return preds.mean(0) if avg_prediction else preds\n","\n","    def train(self, x_train, y_train, lr, epochs, device):\n","        \"\"\" Learn network's weights using SVI. \"\"\"\n","        random.seed(0)\n","        pyro.set_rng_seed(0)\n","        pyro.clear_param_store()\n","\n","        train_loader = DataLoader(dataset=list(zip(x_train, y_train)), \n","                                  batch_size=batch_size, shuffle=False)\n"," \n","        # send bayesian network and deterministic network to device\n","        self.to(device)\n","        self.det_network.to(device)\n","\n","        # ELBO loss minimization\n","        optimizer = pyro.optim.Adam({\"lr\":lr})\n","        elbo = TraceMeanField_ELBO()\n","        svi = SVI(self.model, self.guide, optimizer, loss=elbo)\n","\n","        for epoch in range(epochs):\n","            loss = 0.0\n","\n","            for x_batch, y_batch in train_loader:\n","\n","                x_batch = x_batch.to(device)\n","                y_batch = y_batch.to(device).argmax(-1)\n","                loss += svi.step(x_data=x_batch, y_data=y_batch)\n","\n","            total_loss = loss / len(train_loader.dataset)\n","            print(f\"Epoch {epoch + 1}]\\t loss: {total_loss:.2f}\")\n","          \n","    def save(self, savedir):\n","        \"\"\" Save posterior weights. \"\"\"\n","        os.makedirs(savedir, exist_ok=True)\n","        fullpath = os.path.join(savedir, self.name+\"_weights.pt\")\n","        param_store = pyro.get_param_store()\n","        param_store.save(fullpath)\n","        \n","    def load(self, savedir, device):\n","        \"\"\" Load posterior weights. \"\"\"\n","        fullpath = os.path.join(savedir, self.name+\"_weights.pt\")\n","        param_store = pyro.get_param_store()\n","        param_store.load(os.path.join(savedir, fullpath))\n","        for key, value in param_store.items():\n","            param_store.replace_param(key, value.to(device), value)\n","\n","    def evaluate(self, x_test, y_test, device, n_samples=10, avg_prediction=True):\n","        \"\"\" Evaluate network on test set. \"\"\"\n","        random.seed(0)\n","        pyro.set_rng_seed(0)  \n","\n","        test_loader = DataLoader(dataset=list(zip(x_test, y_test)), \n","                                 batch_size=batch_size, shuffle=False)\n","        \n","        self.to(device)\n","        self.det_network.to(device)\n","\n","        # disable gradients computation\n","        with torch.no_grad():\n","\n","            correct_predictions = 0.0\n","\n","            # compute predictions on mini-batch\n","            for x_batch, y_batch in test_loader:\n","\n","                x_batch = x_batch.to(device)\n","                y_batch = y_batch.to(device).argmax(-1)\n","\n","                outputs = self.forward(x_batch, n_samples=n_samples, avg_prediction=avg_prediction)\n","                predictions = outputs.to(device).argmax(-1)\n","                correct_predictions += (predictions == y_batch).sum().item()\n","\n","            accuracy = 100 * correct_predictions / len(test_loader.dataset)\n","        \n","        return accuracy"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2ixPir2kr8sS","executionInfo":{"status":"ok","timestamp":1627026874509,"user_tz":-120,"elapsed":57303,"user":{"displayName":"Matteo Marturini","photoUrl":"","userId":"15766514266173803551"}},"outputId":"0888d030-7d9a-4da5-986c-98aa945cc0a6"},"source":["x_train, y_train, x_test, y_test, input_shape, output_size = load_mnist(n_inputs=60000)\n","bay_model = BayesianNetwork(input_shape=input_shape, hidden_size=512, output_size=output_size)\n","\n","bay_model.train(x_train=x_train, y_train=y_train, lr=0.01, epochs=5, device=device)\n","bay_model.save(savedir=path)\n","bay_model.load(savedir=path, device=device)\n","\n","accuracy = bay_model.evaluate(x_test, y_test, device=device, n_samples=10)\n","print(\"\\nTest accuracy: %.2f%%\" % (accuracy))"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Epoch 1]\t loss: 12007.44\n","Epoch 2]\t loss: 5297.01\n","Epoch 3]\t loss: 4629.15\n","Epoch 4]\t loss: 4188.66\n","Epoch 5]\t loss: 3768.67\n","\n","Test accuracy: 96.30%\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"U-2W8pSCesfx"},"source":["### Adversarial attacks"]},{"cell_type":"code","metadata":{"id":"2-Nah8yJvjHn"},"source":["def loss_gradient_sign(network, image, label, n_samples=None):\n","    \"\"\" Computes loss gradient sign of `network` w.r.t. `image`. \n","    if `n_samples` is not None, returns the expected loss gradient sign.\n","    \"\"\"\n","\n","    if n_samples is None: # deterministic loss gradient \n","\n","        # activate gradients computation w.r.t. `image`\n","        image.requires_grad = True\n","\n","        output = network.forward(inputs=image) # forward pass\n","        network.zero_grad() # reset gradients\n","\n","        loss = torch.nn.CrossEntropyLoss()(output, label).to(dtype=torch.double)\n","        loss.backward() # backward pass\n","\n","        gradient_sign = image.grad.data.sign() # get gradients w.r.t. `image`\n","\n","    else: # Bayesian loss gradient \n","\n","        sample_idxs = list(range(n_samples))\n","        loss_gradients=[]\n","\n","        for idx in sample_idxs:\n","\n","            # deepcopy avoids unwanted automatic updates \n","            x_copy = copy.deepcopy(image)\n","\n","            # activate gradients computation w.r.t. `image`\n","            x_copy.requires_grad = True\n","\n","            output = network.forward(inputs=x_copy, n_samples=1, sample_idx=idx).to(dtype=torch.double)\n","            loss = torch.nn.CrossEntropyLoss()(output, label)\n","            network.zero_grad()\n","            loss.backward()\n","\n","            # compute loss gradient sign w.r.t. `sample_idx`\n","            loss_gradient = x_copy.grad.data[0].sign()\n","            loss_gradients.append(loss_gradient)\n","\n","        # expected loss gradient sign\n","        gradient_sign = torch.stack(loss_gradients).mean(0)\n","\n","    return gradient_sign\n","\n","def fgsm_attack(network, image, label, epsilon=0.2, n_samples=None):\n","    \"\"\" Performs FGSM attack on the input `image` using `epsilon` perturbations.\n","    If `n_samples` is not None performs a Bayesian attack.\n","    \"\"\"\n","    gradient_sign = loss_gradient_sign(network=network, n_samples=n_samples, image=image, label=label)\n","    perturbed_image = image + epsilon * gradient_sign\n","    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n","    return perturbed_image\n","\n","def attack_network(network, x_test, y_test, device, method=\"fgsm\", hyperparams={}, n_samples=None):\n","    \"\"\" Attacks `network` on `x_test` inputs. \n","    `hyperparams` is a dictionary containing the hyperparameters for the attack.\n","    If `n_samples` is not None performs a Bayesian attack.\n","    \"\"\"\n","    network.to(device)\n","\n","    adversarial_attacks = []\n","\n","    # attack mini-batches\n","    for x, y in zip(x_test, y_test):\n","        image = x.to(device).unsqueeze(0)\n","        label = y.argmax(-1).to(device).unsqueeze(0)\n","        \n","        if method == \"fgsm\":\n","            perturbed_image = fgsm_attack(network=network, image=image, label=label, \n","                                          epsilon=hyperparams['epsilon'], n_samples=n_samples)\n","        else:\n","            raise NotImplementedError\n","\n","        adversarial_attacks.append(perturbed_image)\n","\n","    # list of tensors to tensor\n","    adversarial_attacks = torch.cat(adversarial_attacks)\n","    return adversarial_attacks"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ONm-evD7kCqi"},"source":["# FGSM attack on both networks\n","\n","x_test, y_test = load_mnist(n_inputs=100)[2:4]\n","\n","det_adversarial_attacks = attack_network(network=det_model, x_test=x_test, y_test=y_test, \n","                                        device=device, method=\"fgsm\", hyperparams={'epsilon':0.2})\n","\n","bay_adversarial_attacks = attack_network(network=bay_model, x_test=x_test, y_test=y_test, \n","                                        device=device, method=\"fgsm\", hyperparams={'epsilon':0.2}, n_samples=10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0P4C-YuWkhJE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621415496185,"user_tz":-120,"elapsed":69190,"user":{"displayName":"Ginevra Carbone","photoUrl":"","userId":"02860808768161857230"}},"outputId":"8d5e7869-bcd4-4692-aeac-5636a7b34f61"},"source":["def evaluate_attack(network, x_test, y_test, x_adversarial, device, n_samples=None):\n","\n","    original_accuracy = network.evaluate(x_test, y_test, device=device, n_samples=n_samples)\n","    adversarial_accuracy = network.evaluate(x_adversarial, y_test, device=device, n_samples=n_samples)\n","    print(f\"Test accuracy = {original_accuracy}\\tAdversarial accuracy = {adversarial_accuracy}\")\n","\n","print(\"\\nDeterministic network\")\n","evaluate_attack(network=det_model, x_test=x_test, y_test=y_test, \n","                x_adversarial=det_adversarial_attacks, device=device)\n","\n","print(\"\\nBayesian network\")\n","evaluate_attack(network=bay_model, x_test=x_test, y_test=y_test, \n","                x_adversarial=bay_adversarial_attacks, device=device, \n","                n_samples=10)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","Deterministic network\n","Test accuracy = 99.0\tAdversarial accuracy = 27.0\n","\n","Bayesian network\n","Test accuracy = 98.0\tAdversarial accuracy = 98.0\n"],"name":"stdout"}]}]}